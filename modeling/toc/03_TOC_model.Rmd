---
title: "Testing TOC preds"
author: "Matthew Ross & Sam Struthers-ROSSyndicate"
date: "2025-08-01"
output: html_document
---

# Package load

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source("src/setup_libraries.R")

library(purrr)
library(ggplot2)
library(dplyr)
library(gridExtra)
library(grid)
library(Ckmeans.1d.dp)
library(DiagrammeR)
library(Metrics)
library(caret)
library(glue)
set.seed(123)
```

# Create scaling based on all sensor data

```{r}
# Read in all data to create scaling parameters
all_sensor_data_wide <- read_parquet("data/upper_clp_dss/sensor/prepped/all_sensor_data_2023-03-30_2025-08-27.parquet")

# Use the complete sensor dataset for scaling parameters (assuming sensor has all necessary columns already)
complete_sensor_data <- all_sensor_data_wide %>%
  mutate(month = lubridate::month(DT_round))%>%
  select(FDOM = `FDOM Fluorescence`,
         hrs_since_last_cleaning = hours_since_last_visit,
         Temp = Temperature,
         Sensor_Cond = `Specific Conductivity`,
         Sensor_Turb = Turbidity,
         Chl_a = `Chl-a Fluorescence`, 
         month)%>%
  
  mutate(#capping sensor turb at 1000 for outliers
    Sensor_Turb = ifelse(Sensor_Turb > 1000, 1000,
                         ifelse(Sensor_Turb <= 0, 0.01, Sensor_Turb)), # if turb is zero, replace with 0.01 to avoid division by zero
    log_sensor_turb = log(Sensor_Turb), 
    Chl_a = ifelse(Chl_a == 0,0.0001, Chl_a),# if Chl_A is zero, replace with 0.001 to avoid division by zero
    log_chl_a = log(Chl_a),
    #compute optical bands
    f_c_turb = FDOM/(Chl_a + Sensor_Turb + FDOM))%>%
  #remove NAs
  filter(!is.na(hrs_since_last_cleaning) & !is.na(f_c_turb) & !is.na(Temp)& !is.na(Sensor_Cond))

# Save the original min/max values for each numeric column
scaling_params <- complete_sensor_data %>%
  select(where(is.numeric)) %>%
  summarise(across(everything(), list(min = min, max = max), .names = "{.col}_{.fn}"))

# Save these parameters
#saveRDS(scaling_params, "data/upper_clp_dss/modeling/scaling_parameters_20250820.rds")
# Load saved scaling parameters
#scaling_params <- readRDS("data/upper_clp_dss/modeling/scaling_parameters_20250820.rds")

# Function to apply the same scaling to new data
apply_training_scale <- function(new_data, scaling_params) {
  numeric_cols <- names(select(new_data, where(is.numeric)))
  
  scaled_data <- new_data
  
  for (col in numeric_cols) {
    min_val <- scaling_params[[paste0(col, "_min")]]
    max_val <- scaling_params[[paste0(col, "_max")]]
    
    # Apply same min-max scaling as training data
    scaled_data[[col]] <- (new_data[[col]] - min_val) / (max_val - min_val)
  }
  
  return(scaled_data)
}
```


# Read in Data

```{r}
# Read in all matches data
all_matches <- read_csv(file = 'data/upper_clp_dss/modeling/parsed_data_ROSS_virridy.csv', show_col_types = F) %>%
  mutate(id = as.character(mw_id)) %>%
  mutate(#capping sensor turb at 1000 for outliers
    Sensor_Turb = ifelse(Sensor_Turb > 1000, 1000,
                         ifelse(Sensor_Turb <= 0, 0.001, Sensor_Turb)),
    log_sensor_turb = log(Sensor_Turb), 
    #compute optical bands
    f_c_turb = FDOM/(Chl_a + Sensor_Turb + FDOM), 
    log_chl_a = log(Chl_a))%>%
  #remove NAs
  filter(!is.na(hrs_since_last_cleaning) & !is.na(f_c_turb) & !is.na(Temp)& !is.na(Sensor_Cond))%>%
  mutate(clean_sensor_datetime = parse_date_time(sensor_datetime, orders = c("%Y-%m-%d %H:%M:%S", "%m/%d/%y %H:%M","%Y-%m-%d" )))%>%
  mutate(sensor_datetime = force_tz(clean_sensor_datetime, tzone = 'MST'), 
         month = lubridate::month(sensor_datetime))%>%
  #remove other parameters other than sensor values (to be normalized)
  select(  -NO3, -TN, -DOC, -Kjeldahl, -Phosphorus,  -clean_sensor_datetime, -Turbidity, -Conductivity, -Depth, -Cl, -mw_id)

# Apply scaling to dataset
all_matches_norm <- all_matches %>%
  #remove TOC
  select(-TOC)%>%
  #normalize data based on full sensor set from 01_sensor_data_prep.rmd and the chunk above
  apply_training_scale(., scaling_params)%>%
  #add back in TOC (non normalized)
  mutate(TOC = all_matches$TOC)%>%
  na.omit()

```

# Set aside testing dataset & select features

```{r}
features <- c('FDOM', 'Sensor_Turb', "log_sensor_turb", 'Sensor_Cond', 'Chl_a','Temp','f_c_turb', "log_chl_a" )
target  = "TOC"

all_matches_trimmed <- all_matches_norm%>%
  filter(!(id == "cbri" & between(sensor_datetime, "2024-10-08", "2024-10-10")))%>% #exclude a cbri sample taken during release
  filter(!(id == "pman" & between(sensor_datetime, "2025-05-28", "2025-06-01")))%>% #exclude a pman sample with bad sensor data
  filter( id %nin% c("springcreek", "boxcreek"))


testing <- all_matches_trimmed %>%
  filter((year(sensor_datetime) == 2025 & id %in% c("chd", "sfm", "pbr", "pman", "pbd")))


train_val <- all_matches_trimmed %>%
  anti_join(testing)%>%
  select(id, any_of(features),TOC, sensor_datetime, collector)

```

## Create table of testing site/years vs training site years

```{r}

# Create a summary table of site and years for training/validation and testing datasets
train_val_summary <- train_val %>%
  mutate(year = year(sensor_datetime)) %>%
  group_by(id, year) %>%
  summarise(n_samples = n(), .groups = "drop") %>%
  arrange(id, year)
testing_summary <- testing %>%
  mutate(year = year(sensor_datetime)) %>%
  group_by(id, year) %>%
  summarise(n_samples = n(), .groups = "drop") %>%
  arrange(id, year)

# Combine summaries into one table
summary_table <- bind_rows(
  train_val_summary %>% mutate(dataset = "Train/Val"),
  testing_summary %>% mutate(dataset = "Test")
) %>%
  pivot_wider(names_from = dataset, values_from = n_samples, values_fill = 0) %>%
  arrange(id, year)

# The table should have two groups of columns: Train/Val and Test, with the year in ()

```




# Train all 4 models on train val

## Define and visualize folds

```{r}
# Define validation sets for each fold
val_set_1 <- c( "sfm", "105075514","salyer","10507600",  "penn","archery", "cbri")

val_set_2 <- c("105075583", "archery_virridy", "pbd"  , "105075569", "elc","riverbend"  )

val_set_3 <- c("pfal","105075545","joei",  "lbea", "riverbluffs" , "105075538"  )

val_set_4 <- c("chd",  "105075624",   "udall", "105075552")



# Function to create plots for a given fold
plot_fold <- function(fold_id, train_val) {
  val_set_name <- paste0("val_set_", fold_id)
  val_set <- train_val %>% filter(id %in% get(val_set_name))
  train_set <- train_val %>% filter(id %nin% get(val_set_name))
  
  prop_val <- round(nrow(val_set)/nrow(train_val), 2) * 100
  train_med <- round(median(train_set$TOC, na.rm = TRUE), 2)
  val_med <- round(median(val_set$TOC, na.rm = TRUE), 2)
  
  # Histogram
  hist <- ggplot(train_set, aes(x = TOC)) +
    geom_histogram(bins = 30, fill = "grey") +
    geom_histogram(data = val_set, aes(x = TOC), bins = 30, fill = "#E70870", alpha = 0.5) +
    labs(
      title = paste0("Fold Set ", fold_id, ": ", nrow(val_set), " samples (", prop_val, "%) in validation set"),
      subtitle = paste0("Validation Sites: ", paste(unique(val_set$id), collapse = ", ")),
      x = "TOC (mg/L)"
    ) +
    theme_minimal()
  
  # Boxplot
  box <- ggplot(
    train_set %>% mutate(set = "Train") %>% 
      bind_rows(val_set %>% mutate(set = "Validation")) %>% 
      mutate(set = factor(set, levels = c("Train", "Validation"))),
    aes(x = set, y = TOC, fill = set)
  ) +
    geom_boxplot() +
    scale_fill_manual(values = c("Train" = "#256BF5", "Validation" = "#E70870")) +
    labs(
      title = paste0("Train Median TOC: ",train_med, "\nVal Median TOC: ", val_med),
      x = "",
      y = "TOC (mg/L)",
      fill = "TV Group",
    ) +
    theme_minimal()
  
  # Combine plots
  ggarrange(hist, box, nrow = 1)
}

# Create a list to store all fold plots
fold_plots <- list()
for (i in 1:4) {
  fold_plots[[i]] <- plot_fold(i, train_val)
}
ggarrange(plotlist = fold_plots, ncol = 1)



```

## Visualize TOC distribution in training/validation vs testing sets

```{r}


ggplot(train_val, aes(x = TOC)) +
  geom_histogram(bins = 30, fill = "grey") +
  geom_histogram(data = testing, aes(x = TOC), bins = 30, fill = "#E70870", alpha = 0.5) +
  labs(
    title = paste0("Training/Validation Set: ", nrow(train_val), " samples                Testing Set: ", nrow(testing), " samples"),
    subtitle = paste0("Training TOC Range: ", round(min(train_val$TOC, na.rm = TRUE),2), " - ", round(max(train_val$TOC, na.rm = TRUE),2) , " mg/L (Median: ", round(median(train_val$TOC), 2), ")\nTesting TOC Range: ", round(min(testing$TOC, na.rm = TRUE),2), " - ", round(max(testing$TOC, na.rm = TRUE),2), " mg/L (Median: ", round(median(testing$TOC), 2),")"),
    x = "TOC (mg/L)"
  ) +
  theme_minimal()


```


## Visualize TOC weighting approach

```{r}

# Example data
data <- tibble(toc = seq.int(0, 10, 0.1)) %>%
  # inverse weight: higher TOC -> lower weight
  mutate(weight  = ifelse(toc <= 2.5, 
                          1,                  # flat weight for low TOC
                          1 + 2 *log1p(toc - 2.5))  # smooth increase after 2.5
  )  # simple inverse scaling

# Plotting
ggplot(data, aes(x = toc)) +
  geom_line(aes(y = weight), color = "blue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "red") +
  labs( x = "TOC (mg/L)", y = "Weight", title = "TOC Model Weighting Approach (red line = 1)") +
  theme_minimal()+
  ylim(0,7.5)


```



# Grid search and train models
Create 4 seperate folds and 4 models, with one fold used for validation on each model. 

```{r}
source("src/xgboost_site_stratified_tuning.R")

folds <- tibble(
  fold = 1:4,
  val_ids = list(val_set_1, val_set_2, val_set_3, val_set_4)
)

toc_high_weights <-  function(df) {
  ifelse(df$TOC <= 2.5,1,                  # flat weight for low TOC
         1 + 2 *log1p(df$TOC - 2.5))  # grows slowly, no cap needed
}

model <- xgboost_site_stratified_tuning(
  data = train_val %>% select(TOC, id, any_of(features)),
  weights = toc_high_weights,
  tune_grid = expand.grid(
    nrounds = 10000,
    max_depth = c(2, 3, 4),
    eta = c( 0.01, 0.1),
    gamma = c(0.5, 0.8),
    lambda = c(0, 1),
    alpha = c(0, 1),
    colsample_bytree = c(0.5,0.8),
    min_child_weight = c(2, 4, 6),
    subsample = c(0.5,0.8)
  ),
  target_col = "TOC",
  site_col = "id",
  fold_ids =  folds, 
  units = "mg/L"
)



# Reduce tune grid for reruns (ie. General best params)
# tune_grid = expand.grid(
#        nrounds = 10000,
#        max_depth = c(2, 3, 4),
#        eta = c( 0.005, 0.01, 0.1),
#        gamma = c(0.5, 0.8),
#        lambda = c(0, 1),
#        alpha = c(0, 1),
#        colsample_bytree = c(0.5,0.8),
#        min_child_weight = c(2, 4, 6),
#        subsample = c(0.5,0.8)
#      )
```

## Save files (smaller)
```{r}

small_models <- lapply(model, function(x) {
  m <- x$model   # extract model (xgboost object)
  
  #remove large unnecessary elements 
  if ("trainingData" %in% names(m)) m$trainingData <- NULL
  if ("call" %in% names(m)) m$call <- NULL
  if ("terms" %in% names(m)) m$terms <- NULL
  
  return(m)
})
saveRDS(small_models, file = paste0("data/upper_clp_dss/modeling/model_splits/toc_xgboost_models_light_",Sys.Date(),".rds"))

```


# Read in Model
```{r}

most_recent_file <- list.files("data/upper_clp_dss/modeling/model_splits", pattern = "toc_xgboost_models_light_.*\\.rds", full.names = TRUE) %>%
  tail(1)
model <- readRDS(most_recent_file)
```

## Look at feature importance for each fold

```{r}
importance_list <- lapply(seq_along(model), function(i) {
  fold_model <- model[[i]]
  importance_matrix <- xgb.importance(feature_names = features, model = fold_model)
  importance_df <- as.data.frame(importance_matrix)
  importance_df$Fold <- paste("Fold", i)
  return(importance_df)
})

print(importance_list)
```

## Create plots of training + testing

```{r}

# Function to create plots for a given fold
plot_fold_performance <- function(fold_id, train_val_df, fold_model, target_col = "TOC", units = "mg/L") {
  # Predictions on validation/training set
  val_set_name <- paste0("val_set_", fold_id)
  val_data <- train_val_df %>% filter(id %in% get(val_set_name))
  train_data <- train_val_df %>% filter(id %nin% get(val_set_name))
  target_pred_col <- paste0(target_col, "_guess")
  #convert train_val sets to matrix for prediction
  val_matrix <- val_data[, features]%>%
    mutate(across(everything(), as.numeric)) %>%
    as.matrix()
  train_matrix <- train_data[, features]%>%
    mutate(across(everything(), as.numeric)) %>%
    as.matrix()
  
  #make predictions
  val_data[[target_pred_col]] <-  predict(fold_model, val_matrix, iterationrange = c(1, fold_model$best_iteration))
  val_data$group <-  "Validation"
  train_data[[target_pred_col]] <-  predict(fold_model, train_matrix, iterationrange = c(1, fold_model$best_iteration))
  train_data$group <-  "Train"
  
  # Calculate RMSE/MAE for annotation
  train_rmse <- rmse(train_data[[target_col]],train_data[[target_pred_col]]) %>% round(3)
  val_rmse <- rmse(val_data[[target_col]],val_data[[target_pred_col]]) %>% round(3)
  train_mae <- mae(train_data[[target_col]], train_data[[target_pred_col]]) %>% round(3)
  val_mae <- mae(val_data[[target_col]], val_data[[target_pred_col]]) %>% round(3)
  
  # Create performance plot on Train/val
  # Combine train and val sets for plotting
  data <- bind_rows(train_data, val_data)
  # get plot bounds
  min_val <- min(data[[target_col]], na.rm = TRUE)
  max_val <- max(data[[target_col]], na.rm = TRUE)
  
  plot_range <- max_val - min_val
  box_width <- plot_range * 0.5
  box_height <- plot_range * 0.2
  box_xmin <- min_val + plot_range * 0.02
  box_xmax <- box_xmin + box_width
  box_ymax <- max_val - plot_range * 0.02
  box_ymin <- box_ymax - box_height
  text_x <- (box_xmin + box_xmax) / 2
  text_y1 <- box_ymax - box_height * 0.15
  text_y2 <- box_ymax - box_height * 0.5
  text_y3 <- box_ymax - box_height * 0.85
  
  train_val_plot <- ggplot(data, aes(x = .data[[target_col]], y = .data[[target_pred_col]], color = group))+ #shape = collector)) +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed", size = 1.2) +
    
    # Training points (all same shape)
    geom_point(
      data = filter(data, group == "Train"),
      #shape = 16,  # solid circle
      size = 4,
      alpha = 0.6) +
    geom_point( # Testing points (shape by id)
      data = filter(data, group == "Validation"),
      shape = 17,
      #aes(shape = id),
      size = 4,
      alpha = 0.9
    ) +
    annotate("rect", xmin = box_xmin, xmax = box_xmax, ymin = box_ymin, ymax = box_ymax,
             fill = "white", color = "black", alpha = 1, linewidth = 0.5) +
    annotate("text", x = text_x, y = text_y1, label = paste0("Training samples: n = ", (nrow(data) - nrow(val_data))),
             color = "black", size = 3) +
    annotate("text", x = text_x, y = text_y2, label = paste0("Validation samples: n = ", nrow(val_data)),
             color = "black", size = 3) +
    annotate("text", x = text_x, y = text_y3, label = paste0("Val RMSE: ", val_rmse,
                                                             " ",units,", MAE:", val_mae, " ", units),
             color = "black", fontface = 2, size = 3.5) +
    scale_color_manual(values = c("Train" = "#002EA3", "Validation" = "#FFCA3A")) +
    #scale_shape_manual(values = c("ROSS" = 15, "FC" = 17, "Virridy" = 19)) +
    labs(
      x = paste0("Measured ", target_col, " (", units, ")"),
      y = paste0("Predicted ", target_col, " (", units, ")"),
      color = "Model Group",
      #shape = "Site",
      title = paste0("Model Fold: ", fold_id)
    ) +
    theme_bw(base_size = 16) +
    xlim(min_val, max_val) +
    ylim(min_val, max_val) +
    theme(legend.position = "bottom",
          plot.title = element_text(hjust = 0.5, face = "bold"))
  
  train_val_plot
  
}

# Create a list to store all fold plots
fold_perf_plot <- list()
for (i in 1:4) {
  fold_perf_plot[[i]] <- plot_fold_performance(fold_id = i, fold_model = model[[i]], train_val_df = train_val, target_col = "TOC", units = "mg/L")
}
ggarrange(plotlist = fold_perf_plot, ncol = 2, nrow = 2, common.legend = T, legend = "bottom")

ggsave("data/upper_clp_dss/figures/toc_modeling/performance/toc_model_fold_validation_performance.png", width = 14, height = 10)

```

# Evaluate on Test Set
DO NOT Retrain without large changes

## Calculate performance and apply to testing set

```{r}
# Convert testing and train_val datasets to matrices for prediction

test_matrix <- testing[, features]%>%
  mutate(across(everything(), as.numeric)) %>%
  as.matrix()

train_matrix <- train_val[, features]%>%
  mutate(across(everything(), as.numeric)) %>%
  as.matrix()

# Add predictions from each fold model as new columns
for (i in seq_along(model)) {
  fold_model <- model[[i]]
  col_name <- glue("{target}_guess_fold{i}")
  testing[[col_name]] <- predict(fold_model, test_matrix)
  train_val[[col_name]] <- predict(fold_model, train_matrix)
}

fold_cols <- glue("{target}_guess_fold{seq_along(model)}")
ensemble_col <- glue("{target}_guess_ensemble")
testing[[ensemble_col]] <- rowMeans(testing[, fold_cols])
train_val[[ensemble_col]] <- rowMeans(train_val[, fold_cols])

#Join
all_preds <- bind_rows(testing%>%mutate(group = "Test"), 
                       train_val%>%mutate(group = "Train"))

#compute metrics
metrics_tbl <- map_dfr(c(seq_along(model), "mean"), function(f) {
  col_name <- if (f == "mean") glue(ensemble_col) else glue("{target}_guess_fold{f}")
  
  all_preds %>%
    group_by(group) %>%
    summarise(
      model = as.character(f),
      rmse = rmse(.data[[target]], .data[[col_name]]),
      mae  = mae(.data[[target]], .data[[col_name]]),
      bias = bias(.data[[target]], .data[[col_name]]),
      .groups = "drop"
    )%>%
    ungroup()
})%>%
  arrange(group)

metrics_tbl


```


## Visualize Train Val Test

```{r}
# Function to generate a plot for a given prediction column
plot_train_val_test <- function( train_val_df, test_df, target_col, fold_id) {
  
     if (fold_id == "Ensemble") {
  # --- Collect all test predictions from every fold ---
  test_preds_all <- map_dfc(model, function(m) {
    predict(m, as.matrix(test_df[, features]))
  })
  colnames(test_preds_all) <- paste0("fold_", seq_along(model))
  
  test_preds_all <- test_preds_all %>%
    mutate(id = test_df$id,
           observed = test_df[[target_col]])
  
  test_summary <- test_preds_all %>%
    pivot_longer(starts_with("fold_"), names_to = "fold", values_to = "pred") %>%
    group_by(id, observed) %>%
    summarise(
      pred_mean = mean(pred, na.rm = TRUE),
      pred_min  = min(pred, na.rm = TRUE),
      pred_max  = max(pred, na.rm = TRUE),
      .groups = "drop"
    )
  
  # --- Training predictions (mean across folds) ---
  train_preds_all <- map_dfc(model, function(m) {
    predict(m, as.matrix(train_val_df[, features]), iteration_range = c(1, m$best_iteration))
  })
  colnames(train_preds_all) <- paste0("fold_", seq_along(model))
  
  train_summary <- train_preds_all %>%
    mutate(id = train_val_df$id,
           sensor_datetime = train_val_df$sensor_datetime,
           observed = train_val_df[[target_col]], 
           pred_mean = rowMeans(select(., starts_with("fold_")), na.rm = TRUE))

  # --- Metrics ---
  train_rmse <- rmse(train_summary$observed, train_summary$pred_mean) %>% round(2)
  train_mae  <- mae(train_summary$observed, train_summary$pred_mean) %>% round(2)
  test_rmse  <- rmse(test_summary$observed, test_summary$pred_mean) %>% round(2)
  test_mae   <- mae(test_summary$observed, test_summary$pred_mean) %>% round(2)
  
  # --- Axis limits ---
  min_val <- min(c(test_summary$observed, train_summary$observed), na.rm = TRUE)
  max_val <- max(c(test_summary$observed, train_summary$observed), na.rm = TRUE)
  plot_range <- max_val - min_val
  
  # annotation box coords
  box_width <- plot_range * 0.4
  box_height <- plot_range * 0.2
  box_xmin <- min_val + plot_range * 0.02
  box_xmax <- box_xmin + box_width
  box_ymax <- max_val - plot_range * 0.02
  box_ymin <- box_ymax - box_height
  text_x <- (box_xmin + box_xmax) / 2
  text_y1 <- box_ymax - box_height * 0.15
  text_y2 <- box_ymax - box_height * 0.5
  text_y3 <- box_ymax - box_height * 0.85
  
  # --- Plot ---
  p <- ggplot() +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", size = 1.5) +
  
  # Training points (blue circles)
  geom_point(
    data = train_summary,
    aes(x = observed, y = pred_mean,
        color = "Training", shape = "Training"),
    size = 4, alpha = 0.7
  ) +
  
  # Test points (pink triangles + errorbars)
  geom_errorbar(
    data = test_summary,
    aes(x = observed, ymin = pred_min, ymax = pred_max),
    width = 0.2, color = "#E70870", alpha = 0.6
  ) +
  geom_point(
    data = test_summary,
    aes(x = observed, y = pred_mean,
        color = "Testing", shape = "Testing"),
    size = 4, alpha = 0.9
  ) +
  # Annotation box
  annotate("rect", xmin = box_xmin, xmax = box_xmax, ymin = text_y3, ymax = box_ymax ,
           fill = "white", color = "black", alpha = 1, linewidth = 0.5) +
  annotate("text", x = text_x, y = text_y1,
           label = paste0("Training samples: n = ", nrow(train_summary),
                          "\nTesting samples: n = ", nrow(test_summary)),
           color = "black", size = 4, fontface = 2) +
  annotate("text", x = text_x, y = text_y2,
           label = paste0("Testing RMSE: ", test_rmse,
                          " mg/L\nTesting MAE: ", test_mae, " mg/L"),
           color = "black", fontface = 2, size = 4.5) +
  
  labs(
    x = "Measured TOC (mg/L)",
    y = "Predicted TOC (mg/L)",
    title = "Ensemble Predictions (Mean ± Range across folds)",
    color = "Model Group", shape = "Model Group"
  ) +
    scale_color_manual(values = c("Training" = "#002EA3", "Testing" = "#E70870")) +
    scale_shape_manual(values = c("Training" = 16, "Testing" = 17)) + # 16=circle, 17=triangle
    xlim(min_val, max_val) +
    ylim(min_val, max_val) +
    theme_bw(base_size = 20) +
    ROSS_theme +
    theme(
      plot.title = element_text(hjust = 0.5, face = "bold", size = 18), 
      axis.title.x = element_text(size = 16),
      axis.title.y = element_text(size = 16), 
      legend.text = element_text(size = 14),
      legend.title = element_text(size = 16, face = "bold")
    )
  

  
  return(p)
}

  
  val_set_name <- paste0("val_set_", fold_id)
  val_set <- train_val_df %>% filter(id %in% get(val_set_name))
  train_set <- train_val_df %>% filter(id %nin% get(val_set_name))
  test_set <- test_df 
  
  
  #use the appropirate fold model to predict target column
  fold_model <- model[[fold_id]]
  # Create matrix for train/val/test datasets
  val_matrix <- val_set[, features]%>%
    mutate(across(everything(), as.numeric)) %>%
    as.matrix()
  train_matrix <- train_set[, features]%>%
    mutate(across(everything(), as.numeric)) %>%
    as.matrix()
  test_matrix <- testing[, features]%>%
    mutate(across(everything(), as.numeric)) %>%
    as.matrix()
  # Define prediction column name
  pred_col <- glue("{target}_guess_fold{fold_id}")
  
  # make predictions
  val_set[[pred_col]] <-  predict(fold_model, val_matrix)
  val_set$group <-  "Validation"
  
  train_set[[pred_col]] <-  predict(fold_model, train_matrix)
  train_set$group <-  "Train"
  
  test_set[[pred_col]] <-  predict(fold_model, test_matrix)
  test_set$group <-  "Test"
  
  data <- bind_rows(train_set, val_set, test_set)
  
  
  # Calculate RMSE/MAE for annotation
  train_rmse <- rmse(train_set[[target_col]],train_set[[pred_col]]) %>% round(2)
  val_rmse <- rmse(val_set[[target_col]],val_set[[pred_col]]) %>% round(2)
  train_mae <- mae(train_set[[target_col]], train_set[[pred_col]]) %>% round(2)
  val_mae <- mae(val_set[[target_col]], val_set[[pred_col]]) %>% round(2)
  test_rmse <- rmse(testing[[target_col]], testing[[pred_col]]) %>% round(2)
  test_mae <- mae(testing[[target_col]], testing[[pred_col]]) %>% round(2)
  
  
  min_val <- min(data[[target_col]], na.rm = TRUE)
  max_val <- max(data[[target_col]], na.rm = TRUE)
  plot_range <- max_val - min_val
  
  box_width <- plot_range * 0.5
  box_height <- plot_range * 0.2
  box_xmin <- min_val + plot_range * 0.02
  box_xmax <- box_xmin + box_width
  box_ymax <- max_val - plot_range * 0.02
  box_ymin <- box_ymax - box_height
  text_x <- (box_xmin + box_xmax) / 2
  text_y1 <- box_ymax - box_height * 0.15
  text_y2 <- box_ymax - box_height * 0.5
  text_y3 <- box_ymax - box_height * 0.85
  
  ggplot(data, aes(x = .data[[target_col]], y = .data[[pred_col]], color = group)) +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed", size = 1.2) +
    
    # Training points (all same shape)
    geom_point(
      data = filter(data, group == "Train"),
      shape = 16,  # solid circle
      size = 4,
      alpha = 0.7) +  
    geom_point(
      data = filter(data, group == "Validation"),
      shape = 15,  # solid square
      size = 4,
      alpha = 0.7) + 
    geom_point( # Testing points (shape by id)
      data = filter(data, group == "Test"),
      shape = 17,
      #aes(shape = id),
      size = 4,
      alpha = 0.99
    ) +
    annotate("rect", xmin = box_xmin, xmax = box_xmax, ymin = box_ymin, ymax = box_ymax,
             fill = "white", color = "black", alpha = 1, linewidth = 0.5) +
    annotate("text", x = text_x, y = text_y1, label = paste0("Model Fold: ", fold_id),
             color = "black", size = 4.5, fontface = 2) +
    annotate("text", x = text_x, y = text_y2, label = paste0("Validation RMSE: ", val_rmse, 
                                                             " mg/L, MAE:", val_mae, " mg/L"),
             color = "black", size = 3, fontface = 2) +
    annotate("text", x = text_x, y = text_y3, label = paste0("Testing RMSE: ", test_rmse, 
                                                             " mg/L, MAE:", test_mae, " mg/L"),
             color = "black", fontface = 2, size = 3.5) +
    scale_color_manual(values = c("Train" = "#002EA3","Validation" = "#FFCA3A","Test" = "#E70870"),
                       breaks = c("Train", "Validation", "Test"))+
    #scale_shape_manual(values = c("ROSS" = 15, "FC" = 17, "Virridy" = 19)) +
    labs(
      x = "Measured TOC (mg/L)",
      y = "Predicted TOC (mg/L)",
      color = "Model Group",
      #shape = "Site",
      title = 
    ) +
    xlim(min_val, max_val) +
    ylim(min_val, max_val) +
    theme(
      plot.title = element_text(hjust = 0.5, face = "bold"))+
    ROSS_theme
}

# 1. Plot each fold
for (i in seq_along(fold_cols)) {
  p <- plot_train_val_test(train_val, testing,"TOC", fold_id = i)
  plot(p)
  # ggsave(glue("data/upper_clp_dss/figures/toc_modeling/performance/model_fold_{i}.png"),
  #     plot = p, width = 10, height = 6, dpi = 500)
}

# 2. Single plot with all four folds
fold_plots <- lapply(seq_along(fold_cols), function(i) {
  p <- plot_train_val_test(train_val, testing,"TOC", fold_id = i)
})

ggarrange(plotlist = fold_plots, ncol = 2, nrow = 2, common.legend = TRUE, legend = "top")
ggsave("data/upper_clp_dss/figures/toc_modeling/performance/model_all_folds_TVT.png",
       width = 14, height = 8, dpi = 500)

# 2. Plot ensemble
ensemble <- plot_train_val_test(train_val, testing,"TOC", fold_id = "Ensemble")
ggsave("data/upper_clp_dss/figures/toc_modeling/performance/model_ensemble.png",
       plot = ensemble, width = 12, height = 10, dpi = 500)
```

# Create global model 

```{r}
best_params <- tibble()
for(i in 1:length(model)){
  best_params <- bind_rows(best_params,  model[[i]]$model$params%>%
                             as_tibble()%>%
                             select(-c(objective, eval_metric, validate_parameters))%>%
                             mutate(fold = i))
}
print(best_params)

# Prepare DMatrix objects
dtrain <- xgb.DMatrix(data = as.matrix(train_val[, features]), label = train_val$TOC)
dtest  <- xgb.DMatrix(data = as.matrix(testing[, features]), label = testing$TOC)

watchlist <- list(train = dtrain, eval = dtest)

# Train XGBoost model with all training data and validate on testing sites
xgb_model <- xgb.train(
  params = list(
    objective = "reg:squarederror",
    max_depth = 2,
    eta = 0.01,
    gamma = 0.6,
    colsample_bytree = 0.8,
    min_child_weight = 2,
    subsample = 0.8
  ),
  data = dtrain,
  nrounds = 20000,
  watchlist = watchlist,     
  early_stopping_rounds = 1000,
  print_every_n = 100
)



```



